# RedClaw Environment Configuration
# Copy this file to .env and customize

# ============= LLM Backend =============
# Options: kaggle, ollama, vllm, openai, local
LLM_BACKEND=ollama

# Ollama (default - local)
LLM_API_URL=http://localhost:11434
LLM_MODEL=phi4

# Kaggle Phi-4 (cloud)
# LLM_BACKEND=kaggle
# KAGGLE_API_URL=https://api.kaggle.com/api/v1
# KAGGLE_API_KEY=your_kaggle_api_key
# LLM_MODEL=microsoft/phi-4

# vLLM (local server)
# LLM_BACKEND=vllm
# LLM_API_URL=http://localhost:8000
# LLM_MODEL=microsoft/phi-4

# OpenAI (cloud)
# LLM_BACKEND=openai
# LLM_API_URL=https://api.openai.com/v1
# OPENAI_API_KEY=your_openai_api_key
# LLM_MODEL=gpt-4o-mini

# ============= LLM Settings =============
LLM_MAX_TOKENS=4096
LLM_CONTEXT_WINDOW=8192
LLM_TEMPERATURE=0.7
LLM_TIMEOUT=120

# ============= Agent Settings =============
AGENT_MAX_ITERATIONS=50
AGENT_MAX_RETRIES=3
AGENT_STREAMING=true

# ============= Tool Settings =============
TOOL_TIMEOUT=300
TOOL_MAX_OUTPUT=100000

# ============= RedClaw Settings =============
REDCLAW_DEBUG=false
REDCLAW_VERBOSE=true
REDCLAW_WORKSPACE=~/.redclaw
